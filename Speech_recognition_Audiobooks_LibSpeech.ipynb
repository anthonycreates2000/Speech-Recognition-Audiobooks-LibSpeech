{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6TTSx6FSt9Z"
      },
      "source": [
        "# Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_WPk0lUUX1e",
        "outputId": "8c818f05-07aa-4c4e-ed62-d99352c40b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchaudio) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Collecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from sox) (1.23.5)\n",
            "Installing collected packages: sox\n",
            "Successfully installed sox-1.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install torchaudio\n",
        "! pip install datasets\n",
        "! pip install sox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VyMXHRU8SNno"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import gc\n",
        "import cv2\n",
        "import math\n",
        "import warnings\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import albumentations as A\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "# import torchmetrics\n",
        "import torch.nn.functional as F\n",
        "import PIL\n",
        "import torch.utils.data as data_utils\n",
        "import json\n",
        "import sox\n",
        "import struct\n",
        "\n",
        "# import pytorch_lightning as pl\n",
        "import imutils\n",
        "import zipfile\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.python.client import device_lib\n",
        "from zipfile import ZipFile\n",
        "from IPython import display\n",
        "from torchvision import models, transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c25ZXkZzYHeH"
      },
      "source": [
        "Get the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "755ga1ITYfzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3817b4-dd8e-45b6-fb1c-b5ed2ba66886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-12 15:04:53--  https://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://us.openslr.org/resources/12/train-clean-100.tar.gz [following]\n",
            "--2023-11-12 15:04:54--  http://us.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving us.openslr.org (us.openslr.org)... 46.101.158.64\n",
            "Connecting to us.openslr.org (us.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6387309499 (5.9G) [application/x-gzip]\n",
            "Saving to: ‘libspeech.tar.gz’\n",
            "\n",
            "libspeech.tar.gz    100%[===================>]   5.95G  35.2MB/s    in 2m 57s  \n",
            "\n",
            "2023-11-12 15:07:51 (34.4 MB/s) - ‘libspeech.tar.gz’ saved [6387309499/6387309499]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://www.openslr.org/resources/12/train-clean-100.tar.gz -O libspeech.tar.gz\n",
        "! tar -xzf libspeech.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def open_file(path):\n",
        "  return open(path, mode = \"rb\")"
      ],
      "metadata": {
        "id": "nrYGbznuQTkG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis\n",
        "\n",
        "Note that LibSpeech dataset has a flac format!"
      ],
      "metadata": {
        "id": "MsdpyoGQGfzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Audio File Format Analysis"
      ],
      "metadata": {
        "id": "qJfz1TefKQq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_type(binary_data):\n",
        "  file_type = binary_data.read(4)\n",
        "  return file_type\n",
        "\n",
        "def get_metadata_block_header(binary_data):\n",
        "  METADATA_BLOCK_TYPE = {\n",
        "    0: \"STREAMINFO\",\n",
        "    1: \"PADDING\",\n",
        "    2: \"APPLICATION\",\n",
        "    3: \"SEEKTABLE\",\n",
        "    4: \"VORBIS_COMMENT\",\n",
        "    5: \"CUESHEET\",\n",
        "    6: \"PICTURE\",\n",
        "  }\n",
        "\n",
        "  metadata_block_header_packed = binary_data.read(4)\n",
        "\n",
        "  # Unpack the bytes as an unsigned integer\n",
        "  metadata_block_header_unpacked = struct.unpack('>I', metadata_block_header_packed)[0]\n",
        "\n",
        "  metadata_block_header_unpacked_copied = metadata_block_header_unpacked\n",
        "\n",
        "  # Extract and print 1 bit\n",
        "  sample_rate = (metadata_block_header_unpacked_copied >> 31) & 0x1\n",
        "\n",
        "  # Extract and print the next 7 bits\n",
        "  block_type = (metadata_block_header_unpacked_copied >> 24) & 0b1111111\n",
        "  block_type = METADATA_BLOCK_TYPE[block_type]\n",
        "\n",
        "  # Extract and print the next 24 bits\n",
        "  length_of_metadata = metadata_block_header_unpacked_copied & 0xFFFFFF\n",
        "  return sample_rate, block_type, length_of_metadata\n",
        "\n",
        "def get_metadata_block_streaminfo(binary_data):\n",
        "  \"\"\"\n",
        "  Mandatory information for FLAC.\n",
        "  \"\"\"\n",
        "\n",
        "  minblocksize_packed = binary_data.read(2)\n",
        "  maxblocksize_framesize_packed = binary_data.read(8)\n",
        "  samplerate_nochannels_bits_totalsample_packed = binary_data.read(8)\n",
        "\n",
        "  # Unpack the data using struct\n",
        "  minblocksize_unpacked = struct.unpack(\n",
        "      \">H\", minblocksize_packed\n",
        "  )[0]\n",
        "  maxblocksize_framesize_unpacked = struct.unpack(\n",
        "      \">Q\", maxblocksize_framesize_packed\n",
        "  )[0]\n",
        "  samplerate_nochannels_bits_totalsample_unpacked = struct.unpack(\n",
        "      \">Q\", samplerate_nochannels_bits_totalsample_packed\n",
        "  )[0]\n",
        "\n",
        "  # Extract and print the specified bits\n",
        "  minblocksize_packed_unpacked_copied = minblocksize_unpacked\n",
        "  maxblocksize_framesize_unpacked_copied = maxblocksize_framesize_unpacked\n",
        "  samplerate_nochannels_bits_totalsample_unpacked_copied = samplerate_nochannels_bits_totalsample_unpacked\n",
        "\n",
        "  min_block_size = minblocksize_packed_unpacked_copied\n",
        "\n",
        "  # Extract and print the first 16 bits\n",
        "  max_block_size = (maxblocksize_framesize_unpacked_copied >> 48) & 0xFFFF\n",
        "\n",
        "  # Extract and print the next 24 bits\n",
        "  min_frame_size = (maxblocksize_framesize_unpacked_copied >> 24) & 0xFFFFFF\n",
        "\n",
        "  # Extract and print the next 24 bits\n",
        "  max_frame_size = maxblocksize_framesize_unpacked_copied & 0xFFFFFF\n",
        "\n",
        "  # Extract and print the first 20 bits\n",
        "  sample_rate = (samplerate_nochannels_bits_totalsample_unpacked_copied >> 44) & 0xFFFFF\n",
        "\n",
        "  # Extract and print the next 3 bits\n",
        "  no_channels = (samplerate_nochannels_bits_totalsample_unpacked_copied >> 41) & 0b111\n",
        "  no_channels = no_channels + 1\n",
        "\n",
        "  # Extract and print the next 5 bits\n",
        "  bits = (samplerate_nochannels_bits_totalsample_unpacked_copied >> 36) & 0b11111\n",
        "  bits = bits + 1\n",
        "\n",
        "  # Extract and print the next 36 bits\n",
        "  total_sample = samplerate_nochannels_bits_totalsample_unpacked_copied & 0xFFFFFFFFF\n",
        "\n",
        "  return min_block_size, max_block_size, sample_rate, no_channels, bits, total_sample"
      ],
      "metadata": {
        "id": "g00oJXgbNjEA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "u5JZ_OvbfaQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb3fc0d-4881-4ab4-bf93-412db11045d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'file_type': b'fLaC',\n",
              " 'sample_rate': 16000,\n",
              " 'block_type': 'STREAMINFO',\n",
              " 'length_of_metadata': 34,\n",
              " 'min_block_size': 4096,\n",
              " 'max_block_size': 4096,\n",
              " 'no_channels': 1,\n",
              " 'bits': 16,\n",
              " 'total_sample': 225360}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "def get_audio_format_data(audio_data):\n",
        "  file_type = get_file_type(audio_data)\n",
        "  sample_rate, block_type, length_of_metadata = get_metadata_block_header(\n",
        "      audio_data\n",
        "  )\n",
        "  min_block_size, max_block_size, sample_rate, no_channels, bits, total_sample = get_metadata_block_streaminfo(\n",
        "      audio_data\n",
        "  )\n",
        "\n",
        "  return {\n",
        "      \"file_type\": file_type,\n",
        "      \"sample_rate\": sample_rate,\n",
        "      \"block_type\": block_type,\n",
        "      \"length_of_metadata\": length_of_metadata,\n",
        "      \"min_block_size\": min_block_size,\n",
        "      \"max_block_size\": max_block_size,\n",
        "      \"sample_rate\": sample_rate,\n",
        "      \"no_channels\": no_channels,\n",
        "      \"bits\": bits,\n",
        "      \"total_sample\": total_sample,\n",
        "  }\n",
        "\n",
        "sample_audio_data = open_file(\"/content/LibriSpeech/train-clean-100/103/1240/103-1240-0000.flac\")\n",
        "get_audio_format_data(sample_audio_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spectrum and Waveform Analysis"
      ],
      "metadata": {
        "id": "HHclh_akKbOU"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkYNfuF5+HX3jLgePn3HVB"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}